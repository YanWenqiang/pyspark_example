{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import findspark\n",
    "findspark.init('/opt/spark')\n",
    "import pyspark\n",
    "sc = pyspark.SparkContext(appName=\"test\", master='local')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkFiles, SparkConf\n",
    "from urllib.parse import unquote\n",
    "import sys\n",
    "import re\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import hashlib\n",
    "\n",
    "\n",
    "def strStr(haystack: str, needle: str) -> int:\n",
    "    def KMP(s, p):\n",
    "        \"\"\"\n",
    "        s为主串\n",
    "        p为模式串\n",
    "        如果t里有p，返回打头下标\n",
    "        \"\"\"\n",
    "        nex = getNext(p)\n",
    "        i = 0\n",
    "        j = 0   # 分别是s和p的指针\n",
    "        while i < len(s) and j < len(p):\n",
    "            if j == -1 or s[i] == p[j]: # j==-1是由于j=next[j]产生\n",
    "                i += 1\n",
    "                j += 1\n",
    "            else:\n",
    "                j = nex[j]\n",
    "\n",
    "        if j == len(p): # j走到了末尾，说明匹配到了\n",
    "            return i - j\n",
    "        else:\n",
    "            return -1\n",
    "\n",
    "    def getNext(p):\n",
    "        \"\"\"\n",
    "        p为模式串\n",
    "        返回next数组，即部分匹配表\n",
    "        \"\"\"\n",
    "        nex = [0] * (len(p) + 1)\n",
    "        nex[0] = -1\n",
    "        i = 0\n",
    "        j = -1\n",
    "        while i < len(p):\n",
    "            if j == -1 or p[i] == p[j]:\n",
    "                i += 1\n",
    "                j += 1\n",
    "                nex[i] = j     # 这是最大的不同：记录next[i]\n",
    "            else:\n",
    "                j = nex[j]\n",
    "\n",
    "        return nex\n",
    "\n",
    "    return KMP(haystack, needle)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def uncode(query, method='gb18030'):\n",
    "    new_query = unquote(query, method)\n",
    "    return new_query\n",
    "\n",
    "def clean(query):\n",
    "    L = ['\\b', '\\f', '\\n', '\\r', '\\t', '\\v']\n",
    "    for c in L:\n",
    "        query = query.replace(c, ' ')\n",
    "    return query\n",
    "\n",
    "def url_code(url):\n",
    "    if url.endswith('/'):\n",
    "        url = url[:-1]\n",
    "    if url.startswith('http://'):\n",
    "        url = url[7:]\n",
    "    elif url.startswith('https://'):\n",
    "        url = '@' + url[8:]\n",
    "    return url\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def extract_clicklog(line):\n",
    "    line = line.strip('\\n')\n",
    "    if len(line) == 0:\n",
    "        return []\n",
    "    tmp = line.split('\\t')\n",
    "    if len(tmp) > 5 and (len(tmp)-2) % 4 == 0 and '#' in tmp[5]:\n",
    "        if len(tmp[0].split('#')) == 6:\n",
    "            '''【更旧】搜索展现日志'''\n",
    "            '''缺少stype、chanel、source、isview、exposure、isjuhe、pagetype'''\n",
    "            uid, uuid, page, time, unk1, unk2 = tmp[0].split('#')\n",
    "            query = uncode(tmp[1])\n",
    "            res = [query, [], []]\n",
    "            for d in table:\n",
    "                if strStr(query, d) != -1:\n",
    "                    res[1].append(d)\n",
    "            if len(res[1]) == 0:\n",
    "                return [] \n",
    "            for i in range(2, len(tmp), 4):\n",
    "                wapurl, isclick, clicktime, vwtwpit = tmp[i:i+4]\n",
    "                vrid, web2wap, tc_flag, weburl, title = vwtwpit.split('#')\n",
    "                res[2].append(vrid)\n",
    "            return res \n",
    "\n",
    "        elif len(tmp[0].split('#')) == 9:\n",
    "            '''【旧】搜索展现日志'''\n",
    "            '''缺少isview、exposure、isjuhe'''\n",
    "            uid, uuid, page, time, unk1, unk2, stype, chanel, source = tmp[0].split('#')\n",
    "            query = uncode(tmp[1])\n",
    "            res = [query, [], []]\n",
    "            for d in table:\n",
    "                if strStr(query, d) != -1:\n",
    "                    res[1].append(d)\n",
    "            if len(res[1]) == 0:\n",
    "                return [] \n",
    "            for i in range(2, len(tmp), 4):\n",
    "                wapurl, isclick, clicktime, vwtwpit = tmp[i:i+4]\n",
    "                vrid, web2wap, tc_flag, weburl, pagetype, title = vwtwpit.split('#')\n",
    "                res[2].append(vrid)\n",
    "            return res\n",
    "    elif len(tmp) > 7 and (len(tmp)-2) % 6 == 0 and '#' in tmp[7]:\n",
    "        '''【新】带title的搜索展现日志'''\n",
    "        uid, uuid, page, time, unk1, unk2, stype, chanel, source = tmp[0].split('#')\n",
    "        query = uncode(tmp[1])\n",
    "        res = [query, [], []]\n",
    "        for d in table:\n",
    "            if strStr(query, d) != -1:\n",
    "                res[1].append(d)\n",
    "        if len(res[1]) == 0:\n",
    "            return [] \n",
    "        for i in range(2, len(tmp), 6):\n",
    "            wapurl, isview, exposure, isclick, clicktime, vwtwpit = tmp[i:i+6]\n",
    "            vrid, web2wap, tc_flag, weburl, pagetype, isjuhe, title = vwtwpit.split('#')\n",
    "            res[2].append(vrid)\n",
    "        return res\n",
    "    return []\n",
    "    \n",
    "def mergeAndMove(line):\n",
    "    key, value = line[0], line[1]\n",
    "    n = len(value)\n",
    "    keywords = set()\n",
    "    for i in range(n):\n",
    "        for w in value[i][0]:\n",
    "            keywords.add(w)\n",
    "    vrid = value[0][1]\n",
    "    return [key, list(keywords), vrid, n]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TABLE=\"viewfs://nsX/user/dmplt/yanwenqiang/operation_table.txt\"\n",
    "INPUT=\"viewfs://nsX/user/webrank/clicklog/ms_title/202010/20201020/part*\"\n",
    "OUTPUT=\"viewfs://nsX/user/dmplt/yanwenqiang/ms_title/202010/20201020\"\n",
    "\n",
    "table_path = \"viewfs://nsX/user/dmplt/yanwenqiang/tmp_table.txt\"\n",
    "table = sc.textFile(table_path)\n",
    "table = table.collect()\n",
    "\n",
    "\n",
    "click_path = \"/user/webrank/clicklog/ms_title/202007/20200715/part-r-00299.lzo\"\n",
    "clickInput = sc.textFile(INPUT, use_unicode=True)\n",
    "clickRdd = clickInput.map(extract_clicklog).filter(lambda x: x and len(x) != 0) # [query, [keywords], [vrids]]\n",
    "clickPair = clickRdd.map(lambda x: (x[0], x[1:])) # (query, [[keywords], [vrid]])\n",
    "\n",
    "\n",
    "clickPairGroupByKey = clickPair.groupByKey().mapValues(list) # (query, [([keywords], [vrids]), ([keywords], [vrids]), ([keywords], [vrids])])\n",
    "clickPairGroupByKey.cache()\n",
    "\n",
    "clickMergeAndMove = clickPairGroupByKey.map(mergeAndMove) # [query, keywords, vrids, n]\n",
    "\n",
    "clickJson = clickMergeAndMove.map(lambda x: {\"query\": x[0], \"words\": x[1], \"vrids\": x[2], \"count\": x[3]}).coalesce(1)\n",
    "\n",
    "# pickle_path = \"viewfs://nsX/user/dmplt/yanwenqiang/test\"\n",
    "\n",
    "# clickJson.saveAsPickleFile(pickle_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = clickJson.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python36",
   "language": "python",
   "name": "python36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
